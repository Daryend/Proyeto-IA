# Buscador del Libro de IA â€” Chatbot Conversacional

Sistema completo de bÃºsqueda semÃ¡ntica en PDF usando embeddings, FAISS y una interfaz web.

## CaracterÃ­sticas
- ğŸ“„ **ExtracciÃ³n de PDF**: PyPDF2
- ğŸ“š **Chunking**: FragmentaciÃ³n inteligente de texto
- ğŸ§  **Embeddings**: sentence-transformers (all-MiniLM-L6-v2)
- ğŸ” **BÃºsqueda**: FAISS + similitud coseno (fallback numpy)
- ğŸ–¥ï¸ **Interfaz**: Flask con HTML/CSS puro
- ğŸ’¬ **CLI**: Modo interactivo por lÃ­nea de comandos

## Requisitos
- Windows PowerShell (o cmd)
- Python 3.8+

## InstalaciÃ³n

1) Crear entorno virtual:
```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

2) Extraer y generar embeddings (se ejecuta una sola vez):
```powershell
& ".venv\Scripts\python.exe" scripts\extract_pdf.py --pdf "Data/FUNDAMENTO+DE+LA+IA+volumen+I.pdf"
& ".venv\Scripts\python.exe" scripts\chunk_text.py --input "Data/FUNDAMENTO+DE+LA+IA+volumen+I.txt"
& ".venv\Scripts\python.exe" scripts\generate_embeddings.py --chunks "Data/chunks.jsonl"
```

## Uso

### OpciÃ³n 1: Interfaz Web (Recomendado)
```powershell
& ".venv\Scripts\python.exe" scripts\app_flask.py
```
Abre en el navegador: **http://127.0.0.1:5000**

CaracterÃ­sticas:
- Escribe preguntas sobre el libro
- Ajusta Top K (cuÃ¡ntos fragmentos) y umbral de similitud
- Ver fragmentos relevantes o mensaje de "no encontrado"

### OpciÃ³n 2: CLI Interactivo
```powershell
& ".venv\Scripts\python.exe" scripts\chat_cli.py
```

Luego escribe tus preguntas (salir con "exit" o Ctrl+C):
```
Pregunta: Â¿QuÃ© es inteligencia artificial?
```

### OpciÃ³n 3: Consulta Puntual
```powershell
& ".venv\Scripts\python.exe" scripts\chat_cli.py --ask "Â¿QuÃ© es machine learning?"
```

## Archivos Generados
- `Data/FUNDAMENTO+DE+LA+IA+volumen+I.txt` â†’ Texto extraÃ­do del PDF
- `Data/chunks.jsonl` â†’ Fragmentos en formato JSONL (586 chunks)
- `Data/embeddings.npz` â†’ Vectores numÃ©ricos (numpy)
- `Data/metadata.jsonl` â†’ Metadatos de los chunks

## Estructura de Scripts
```
scripts/
â”œâ”€â”€ extract_pdf.py        â†’ Extrae texto desde PDF
â”œâ”€â”€ chunk_text.py         â†’ Fragmenta texto en chunks
â”œâ”€â”€ generate_embeddings.py â†’ Genera embeddings con sentence-transformers
â”œâ”€â”€ search_engine.py      â†’ Motor de bÃºsqueda (FAISS/numpy)
â”œâ”€â”€ chat_cli.py          â†’ CLI para consultas
â””â”€â”€ app_flask.py         â†’ Servidor web Flask
```

## ConfiguraciÃ³n
- **Modelo de embeddings**: `all-MiniLM-L6-v2` (rÃ¡pido, 384-dim)
- **Umbral por defecto**: 0.60 (similitud mÃ­nima)
- **Top K por defecto**: 3 (fragmentos devueltos)

## Notas
- La primera ejecuciÃ³n de generaciÃ³n de embeddings descargarÃ¡ el modelo (~30 MB).
- La bÃºsqueda es offline (todo corre localmente).
- Sin dependencias de APIs externas (todo open-source).
